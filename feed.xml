<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://habeeb3579.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://habeeb3579.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-11T04:37:26+00:00</updated><id>https://habeeb3579.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">Building a Github Chat Interface with LangChain, LM Studio, and FAISS</title><link href="https://habeeb3579.github.io/blog/2024/Gitchat/" rel="alternate" type="text/html" title="Building a Github Chat Interface with LangChain, LM Studio, and FAISS"/><published>2024-05-26T14:30:16+00:00</published><updated>2024-05-26T14:30:16+00:00</updated><id>https://habeeb3579.github.io/blog/2024/Gitchat</id><content type="html" xml:base="https://habeeb3579.github.io/blog/2024/Gitchat/"><![CDATA[<p>In this tutorial, we’ll explore using LangChain, LM Studio, and FAISS to create a chat interface for interacting with Github repositories. This project will involve cloning a Github repo using GitLoader from LangChain, splitting the repository into chunks of text with a recursive text splitter, creating a vector database for these split documents using FAISS, and connecting user queries to a local LM Studio for answering questions about the repository. Finally, we’ll deploy the project using Docker and create a Streamlit app where users can supply a Github repo and ask questions about it.</p> <h4 id="cloning-github-repo-with-langchains-gitloader">Cloning Github Repo with LangChain’s GitLoader</h4> <p>We’ll use LangChain’s GitLoader to clone the desired Github repository. This allows us to access the repository’s contents programmatically. You may need to authenticate with github (refer to <a href="https://github.com/gitpython-developers/GitPython">GitPython</a>)</p> <h4 id="connecting-user-queries-to-lm-studio">Connecting User Queries to LM Studio</h4> <p>Users will interact with the chat interface by supplying questions about the Github repository. These queries will be connected to a local instance of LM Studio (defined as llm), a powerful language model fine-tuned for generating human-like responses. LM Studio will answer the user’s questions based on the information stored in the vector database.</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/gitload_1.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <p>Note: repo_path is the path to save the cloned repo and branch is the branch of the repo to be cloned.</p> <h4 id="splitting-repo-into-text-chunks">Splitting Repo into Text Chunks</h4> <p>Next, we’ll use a recursive text splitter to divide the repository’s contents into manageable text chunks. This step is crucial for processing and analyzing large volumes of text efficiently. {::nomarkdown}</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/gitload_2.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <p>{:/nomarkdown}</p> <p>Note that we overlap each chunk by 20 characters to capture more context about the chunks.</p> <h4 id="creating-vector-database-with-faiss">Creating Vector Database with FAISS</h4> <p>Once we have the text chunks, we’ll create a vector database using FAISS.</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/gitload_3.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <h4 id="building-streamlit-app-and-docker-deployment">Building Streamlit App and Docker Deployment</h4> <p>Finally, we’ll build a user-friendly Streamlit app where users can input the Github repository and their questions. The app will communicate with the backend components, including LangChain, FAISS, and LM Studio, to provide seamless interaction.</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/gitload_4.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <p>We’ll containerize the entire project using Docker for easy deployment and scalability.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Screenshot%202024-05-27%20at%2012.19.16%E2%80%AFPM.png" sizes="95vw"/> <img src="/assets/img/Screenshot%202024-05-27%20at%2012.19.16%E2%80%AFPM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Screenshot%202024-05-27%20at%2012.19.44%E2%80%AFPM.png" sizes="95vw"/> <img src="/assets/img/Screenshot%202024-05-27%20at%2012.19.44%E2%80%AFPM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Once the docker is up and running, the app can be accessed at http://localhost:8501</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Screenshot%202024-05-27%20at%2012.31.23%E2%80%AFPM.png" sizes="95vw"/> <img src="/assets/img/Screenshot%202024-05-27%20at%2012.31.23%E2%80%AFPM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>The full implementation of the components of the project will be uploaded on my GitHub page!</p>]]></content><author><name></name></author><category term="NLP"/><category term="LangChain,"/><category term="LMStudio,"/><category term="FAISS,"/><category term="Docker,"/><category term="Github"/><summary type="html"><![CDATA[Learn how to leverage LangChain, LM Studio, and FAISS to create a chat interface for Github repositories.]]></summary></entry></feed>